
# OpenAI Responses API â€” Python Advanced Cheatsheet

The **Responses API** lets you generate text, code, or structured outputs and connect to external **tools** (functions, APIs, workflows, or agents).  
It is **stateless by default**, but you can manage **sessions** and simulate **memory**.

Endpoint:
```
POST https://api.openai.com/v1/responses
```
ðŸ“– Official docs: [Responses API](https://platform.openai.com/docs/api-reference/responses), [Structured outputs](https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses), [Streaming](https://platform.openai.com/docs/guides/streaming-responses?api-mode=responses)

---

## 1) Quickstart: Basic Text Generation
âž¡ Generate text by passing a string input.
```python
resp = client.responses.create(
    model="gpt-4.1",
    input="Tell me a three sentence bedtime story about a unicorn."
)
print(resp.output_text)
```

---

## 2) Structured Output (JSON Schema)
âž¡ Force the model to return valid JSON that matches your schema.
```python
resp = client.responses.create(
    model="gpt-4.1",
    input="Extract name and email from: 'Contact Jane Doe <jane@example.com>'",
    text={
        "format": {
            "type": "json_schema",
            "name": "ContactExtraction",
            "strict": True,
            "schema": {
                "type": "object",
                "properties": {
                    "name": {"type": "string"},
                    "email": {"type": "string", "format": "email"}
                },
                "required": ["name","email"],
                "additionalProperties": False
            }
        }
    }
)
print(resp.output_parsed)
```

---

## 3) Tools = Function Calling
âž¡ Define functions (APIs, workflows, agents) that the model can call.
```python
tools = [
  {
    "type": "function",
    "function": {
      "name": "get_weather",
      "description": "Get weather for a city",
      "parameters": {
        "type": "object",
        "properties": {"city": {"type": "string"}},
        "required": ["city"]
      }
    }
  }
]

def get_weather(city: str):
    return {"city": city, "temp_f": 72}

resp = client.responses.create(
    model="gpt-4.1",
    input="Check Boston weather",
    tools=tools,
    tool_choice="auto"
)
```

---

## 4) Tools as API Calls / Workflows / Agents
âž¡ A tool can wrap an API call, trigger a workflow, or delegate to another agent.

---

## 5) Tool + Structured Output Together
âž¡ Combine tool calling with validated JSON outputs.
```python
resp = client.responses.create(
    model="gpt-4.1",
    input="Check status of order ORD-123",
    tools=[...],
    text={
        "format": {
            "type": "json_schema",
            "name": "OrderStatus",
            "strict": True,
            "schema": {
                "type": "object",
                "properties": {
                    "order_id": {"type": "string"},
                    "status": {"type": "string"}
                },
                "required": ["order_id","status"]
            }
        }
    }
)
```

---

## 6) Streaming Responses
âž¡ Stream tokens and events in real-time.
```python
with client.responses.stream(
    model="gpt-4.1",
    input="Draft a friendly email about tomorrow's meetup.",
) as stream:
    for event in stream:
        if event.type == "response.output_text.delta":
            print(event.delta, end="", flush=True)
    final = stream.get_final_response()
```

---

## 7) Sessions & Memory

### 7.1 No implicit memory
âž¡ Each call is stateless; nothing is remembered automatically.

### 7.2 Conversation-style context
âž¡ Pass previous messages (system, user, assistant) as input.
```python
messages = [
    {"role": "system", "content": "You are a helpful assistant."},
    {"role": "user", "content": "Hi, who won the World Cup in 2018?"},
    {"role": "assistant", "content": "France won the 2018 FIFA World Cup."},
    {"role": "user", "content": "Cool, who was the top scorer?"}
]

resp = client.responses.create(
    model="gpt-4.1", 
    input=messages
)
print(resp.output_text)
```

### 7.3 Sessions
âž¡ Create a session to reuse defaults (instructions, tools, formats).
```python
session = client.sessions.create(
    model="gpt-4.1",
    instructions="You are a financial advisor bot."
)

resp = client.responses.create(
    model="gpt-4.1",
    session=session.id,
    input="Whatâ€™s a good ETF strategy for 30 years?"
)
```

### 7.4 Application-managed memory
âž¡ Store conversation/user state in your DB and feed it back into inputs.

---

## 8) Useful Knobs
âž¡ Control randomness, length, and determinism.
```python
resp = client.responses.create(
    model="gpt-4.1-mini",
    input="Summarize yesterday's standup",
    temperature=0.3,
    max_output_tokens=200,
    seed=1234
)
```

---

## âœ… Summary
- **Responses API** = stateless text/code/JSON generation.  
- **Tools** = APIs, workflows, or agents callable by the model.  
- **Sessions** = reuse defaults; not true memory.  
- **Memory** = managed by your app (pass past context).  
- **Streaming** = token-by-token responses.  

---

### References
- Responses API: https://platform.openai.com/docs/api-reference/responses  
- Structured outputs: https://platform.openai.com/docs/guides/structured-outputs?api-mode=responses  
- Streaming: https://platform.openai.com/docs/guides/streaming-responses?api-mode=responses  
- Python SDK: https://github.com/openai/openai-python  
